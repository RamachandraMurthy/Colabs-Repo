{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvl6Mqe0r3I7GeRD2vEU1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamachandraMurthy/Colabs-Repo/blob/master/Certified_Langchain_Directory_loader_V2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program by Ramachandra Murthy\n",
        "\n",
        "03/28/2023\n",
        "\n",
        "This is a perfect library which loads the files from a given directory. It goes in to recursive in to sub folders as well. This can be used as a initial program."
      ],
      "metadata": {
        "id": "TcNu0aD2CJPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Directory Loader from the Langchain github repository. This is alternate to my previous version."
      ],
      "metadata": {
        "id": "zDKZQpbNhiqD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i06az7nphhFa"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q unstructured\n",
        "!pip install -q unstructured[local-inference]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Restart the runtime*"
      ],
      "metadata": {
        "id": "ES4Zc4qS1dIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CSVLoader class\n",
        "from csv import DictReader\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders.base import BaseLoader\n",
        "\n",
        "class CSVLoader(BaseLoader):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_path: str,\n",
        "        source_column: Optional[str] = None,\n",
        "        csv_args: Optional[Dict] = None,\n",
        "        encoding: Optional[str] = None,\n",
        "    ):\n",
        "        self.file_path = file_path\n",
        "        self.source_column = source_column\n",
        "        self.encoding = encoding\n",
        "        if csv_args is None:\n",
        "            self.csv_args = {\n",
        "                \"delimiter\": \",\",\n",
        "                \"quotechar\": '\"',\n",
        "            }\n",
        "        else:\n",
        "            self.csv_args = csv_args\n",
        "\n",
        "    def load(self) -> List[Document]:\n",
        "        docs = []\n",
        "\n",
        "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
        "            csv = DictReader(csvfile, **self.csv_args)\n",
        "            for i, row in enumerate(csv):\n",
        "                content = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in row.items())\n",
        "                if self.source_column is not None:\n",
        "                    source = row[self.source_column]\n",
        "                else:\n",
        "                    source = self.file_path\n",
        "                metadata = {\"source\": source, \"row\": i}\n",
        "                doc = Document(page_content=content, metadata=metadata)\n",
        "                docs.append(doc)\n",
        "\n",
        "        return docs\n"
      ],
      "metadata": {
        "id": "CuYuMBSYO47k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries and define DirectoryLoader class\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Type, Union\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders.base import BaseLoader\n",
        "from langchain.document_loaders.html_bs import BSHTMLLoader\n",
        "from langchain.document_loaders.text import TextLoader\n",
        "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
        "\n",
        "FILE_LOADER_TYPE = Union[\n",
        "    Type[UnstructuredFileLoader], Type[TextLoader], Type[BSHTMLLoader]\n",
        "]\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def _is_visible(p: Path) -> bool:\n",
        "    parts = p.parts\n",
        "    for _p in parts:\n",
        "        if _p.startswith(\".\"):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "class DirectoryLoader(BaseLoader):\n",
        "    \"\"\"Loading logic for loading documents from a directory.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        path: str,\n",
        "        glob: str = \"**/[!.]*\",\n",
        "        silent_errors: bool = False,\n",
        "        load_hidden: bool = False,\n",
        "        loader_cls: FILE_LOADER_TYPE = UnstructuredFileLoader,\n",
        "        recursive: bool = False,\n",
        "    ):\n",
        "        self.path = path\n",
        "        self.glob = glob\n",
        "        self.load_hidden = load_hidden\n",
        "        self.loader_cls = loader_cls\n",
        "        self.silent_errors = silent_errors\n",
        "        self.recursive = recursive\n",
        "\n",
        "    def load(self) -> List[Document]:\n",
        "        p = Path(self.path)\n",
        "        docs = []\n",
        "        items = p.rglob(self.glob) if self.recursive else p.glob(self.glob)\n",
        "        for i in items:\n",
        "            if i.is_file():\n",
        "                if _is_visible(i.relative_to(p)) or self.load_hidden:\n",
        "                    try:\n",
        "                        if i.suffix == \".csv\":\n",
        "                            sub_docs = CSVLoader(str(i)).load()\n",
        "                        else:\n",
        "                            sub_docs = self.loader_cls(str(i)).load()\n",
        "                        docs.extend(sub_docs)\n",
        "                    except Exception as e:\n",
        "                        if self.silent_errors:\n",
        "                            logger.warning(e)\n",
        "                        else:\n",
        "                            raise e\n",
        "        return docs\n",
        "\n",
        "    def list_files(self) -> List[str]:\n",
        "        p = Path(self.path)\n",
        "        file_paths = []\n",
        "        items = p.rglob(self.glob) if self.recursive else p.glob(self.glob)\n",
        "        for i in items:\n",
        "            if i.is_file():\n",
        "                if _is_visible(i.relative_to(p)) or self.load_hidden:\n",
        "                    file_paths.append(str(i))\n",
        "        return file_paths\n"
      ],
      "metadata": {
        "id": "kDLANSDjOelN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "faEktf_DOrwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca365770-caed-401d-d1e5-495747db939e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DirectoryLoader\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Data/\"\n",
        "glob_pattern = \"**/[!.]*\"\n",
        "recursive = True\n",
        "\n",
        "loader = DirectoryLoader(path, glob=glob_pattern, recursive=recursive)"
      ],
      "metadata": {
        "id": "b3ja410TOvSb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List and sort file names, and print the summary\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "file_names = loader.list_files()\n",
        "sorted_file_names = sorted(file_names, key=lambda x: Path(x).suffix)\n",
        "file_type_counts = defaultdict(int)\n",
        "for file_name in sorted_file_names:\n",
        "    file_type = Path(file_name).suffix\n",
        "    file_type_counts[file_type] += 1\n",
        "\n",
        "total_files = len(sorted_file_names)\n",
        "unique_file_types = len(file_type_counts)\n",
        "\n",
        "print(f\"Total Files: {total_files}\")\n",
        "print(f\"Unique File Types: {unique_file_types}\")\n",
        "print(\"File Type Counts:\")\n",
        "for file_type, count in file_type_counts.items():\n",
        "    print(f\"{file_type}: {count}\")\n",
        "\n",
        "print(\"\\nFile Names:\")\n",
        "for file_name in sorted_file_names:\n",
        "    print(file_name)\n"
      ],
      "metadata": {
        "id": "fX5UWjXKO1O6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c96e4f-874b-4f8e-f524-59d5e1029623"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Files: 9\n",
            "Unique File Types: 4\n",
            "File Type Counts:\n",
            ".csv: 1\n",
            ".pdf: 4\n",
            ".pptx: 1\n",
            ".txt: 3\n",
            "\n",
            "File Names:\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/Analytics Team.csv\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/DXC Time Entry Policy.pdf\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/Code of Conduct-English.pdf\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/DXC Information Security Policy.pdf\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/DXC IT Mobility Policy.pdf\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/Test.pptx\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/Get & Give feedback.txt\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/Annual Leave.txt\n",
            "/content/drive/MyDrive/Colab Notebooks/Data/DXC Time.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With the following code to load multiple files from the same directory:\n",
        "data = []\n",
        "file_data = loader.load()\n",
        "data.extend(file_data)"
      ],
      "metadata": {
        "id": "SPPapb6gkDuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f852174e-d5fb-4e4f-cb1a-a99fcfc81b0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk your data up into smaller documents\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)\n",
        "print(f'Now you have {len(texts)} documents')\n"
      ],
      "metadata": {
        "id": "LYYZefe0kNVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a173b03b-ee96-4a04-a895-b421d198d380"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 3112 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pinecone-client\n",
        "!pip install -q openai\n",
        "\n",
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "import pinecone\n",
        "import openai"
      ],
      "metadata": {
        "id": "pTX44uCZk1tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafc7f51-e0f3-41d4-e681-c68a0f65d9b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = \"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\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "# Set your Pinecone API key and environment\n",
        "pinecone.api_key = \"9ded3df6-4867-42af-bcd6-56c365484778\"  # Replace with your actual Pinecone API key\n",
        "pinecone_api_env = \"us-central1-gcp\"  # Replace with your Pinecone environment\n"
      ],
      "metadata": {
        "id": "ZuKSLluYkymQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings of your documents to get ready for semantic search\n",
        "# Please note the index name is from pinecone service\n",
        "# Pinecone.io (https://app.pinecone.io)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
        "pinecone.init(api_key=pinecone.api_key, environment=pinecone_api_env)\n",
        "index_name = \"dxcpolicy\"\n",
        "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "78bgN3aGkeFU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the QA chain with the OpenAI language model\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai.api_key)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "Boqm5MrNlQ1u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------"
      ],
      "metadata": {
        "id": "14woHlbilU3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test below before testing it thru gradio interface"
      ],
      "metadata": {
        "id": "gUT-cAvelZwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many are listed under Ramachandra Murthy\"\n",
        "docs = docsearch.similarity_search(query, include_metadata=True)"
      ],
      "metadata": {
        "id": "cNmPbwZclW6a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "6H8zrFcIldZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "947eb503-2d10-4798-d8fd-c9d66ae8d725"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' There are four people listed under Ramachandra Murthy: Ramachandra Murthy, Iris Bordey-Choi, Andre van Beuzekom, and Ericka May R Tolentino.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------"
      ],
      "metadata": {
        "id": "tTzj7YL7lV22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "!pip install --upgrade pillow\n"
      ],
      "metadata": {
        "id": "ygy7zCynoPZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac825dad-ae7f-4d3f-b133-bca6819b4130"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "xoDgXyVKphJt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search_qa(query):\n",
        "    if query:\n",
        "        # Perform a similarity search on the document embeddings\n",
        "        docs = docsearch.similarity_search(query, include_metadata=True)\n",
        "\n",
        "        # Run the QA chain with the found documents and the query\n",
        "        answer = chain.run(input_documents=docs, question=query)\n",
        "        return answer\n",
        "\n",
        "# Create Gradio interface for the semantic search and question-answering process\n",
        "def launch_gradio_interface():\n",
        "    inputs = gr.inputs.Textbox(lines=7, label=\"Ask a question\")\n",
        "    outputs = gr.outputs.Textbox(label=\"Answer\")\n",
        "\n",
        "    gr.Interface(fn=semantic_search_qa, inputs=inputs, outputs=outputs, title=\"DXC Policy Search and QA by Ramachandra Murthy\",\n",
        "                 description=\"Ask any DXC policy question\",\n",
        "                 theme=\"compact\").launch(share=True)"
      ],
      "metadata": {
        "id": "dAFK8HXPoX9z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the Gradio interface function\n",
        "launch_gradio_interface()"
      ],
      "metadata": {
        "id": "EivDnQCSoZxp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "60cf8f2b-9cba-4df6-e87c-3f8f1b65c6ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/blocks.py:503: UserWarning: Cannot load compact. Caught Exception: The space compact does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://26476e75105f444b16.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26476e75105f444b16.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}